{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyn2s2+yrfmE+2l9hGcnqK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akr1701/assignment-2-data-assignment/blob/main/File_%26Exceptional_Handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXTNUSf1MkmC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Discuss the  scenarios where  multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.  \n",
        "\n",
        "Choosing between multithreading and multiprocessing in Python depends on the nature of the task and how the Global Interpreter Lock (GIL) affects the execution. Here’s a breakdown of scenarios where each is preferable:\n",
        "\n",
        "### 1. Multithreading\n",
        "**Scenarios Where Multithreading Is Preferable:**\n",
        "- **I/O-bound tasks**: Multithreading is beneficial when tasks are waiting for I/O operations to complete, such as file reading/writing, network requests, or database interactions. Since these tasks spend a lot of time waiting, threads can be used to handle multiple operations concurrently.\n",
        "    - *Examples*: Web scraping, handling multiple web server requests, downloading files, reading from sensors.\n",
        "- **Lightweight tasks with shared memory**: When tasks need to share data between them and require minimal CPU processing, threads can be useful as they share the same memory space, allowing easier data exchange without the need for inter-process communication (IPC).\n",
        "    - *Examples*: Real-time UI updates, chat applications, background tasks like notifications.\n",
        "- **Tasks that require fast context switching**: Threads are lighter than processes, and the overhead for context switching is lower, which can be useful when tasks need frequent switching but minimal processing.\n",
        "    - *Examples*: Background tasks running alongside a main program, like spell-checking in a word processor.\n",
        "\n",
        "### 2. Multiprocessing\n",
        "**Scenarios Where Multiprocessing Is Preferable:**\n",
        "- **CPU-bound tasks**: For tasks that involve heavy computation, multiprocessing is more effective because it can bypass the limitations of the GIL by running each process in its own interpreter instance. This allows full utilization of multiple CPU cores.\n",
        "    - *Examples*: Data analysis, machine learning model training, image processing, large-scale mathematical computations.\n",
        "- **Tasks that need true parallelism**: Since each process runs independently, multiprocessing can achieve true parallelism. This is especially useful when tasks are not dependent on each other.\n",
        "    - *Examples*: Parallel data processing, batch processing tasks, simulations.\n",
        "- **Memory isolation requirements**: Processes have separate memory spaces, which can prevent issues related to shared memory. This makes multiprocessing a better choice when tasks need to be isolated from each other to avoid side effects.\n",
        "    - *Examples*: Running different applications, sandboxing, testing different scenarios without interference.\n",
        "\n",
        "### Summary\n",
        "- **Multithreading**: Best for I/O-bound tasks, lightweight tasks, and scenarios where tasks need to share data and memory. It is less effective for CPU-bound tasks due to the GIL.\n",
        "- **Multiprocessing**: Best for CPU-bound tasks, scenarios requiring true parallelism, and tasks where memory isolation is important. It can take advantage of multiple cores, bypassing the GIL’s limitations.\n",
        "\n",
        "Understanding the nature of the task (I/O-bound vs. CPU-bound) and the need for shared memory or isolation will guide the choice between multithreading and multiprocessing."
      ],
      "metadata": {
        "id": "Bd5JqhQ5Nhv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Describe  what a process pool is and  how it helps in managing multiple process efficiently .\n",
        "\n",
        "A **process pool** is a programming construct used to manage a collection of worker processes that can execute tasks concurrently. It simplifies the handling of multiple processes by creating and managing a fixed number of processes, reusing them to execute tasks, and efficiently distributing work.\n",
        "\n",
        "### Key Features of a Process Pool:\n",
        "1. **Fixed Number of Processes**: A process pool initializes a predefined number of processes (workers) when it starts. This allows for better resource management since the system knows the maximum number of processes that will be running at any given time.\n",
        "2. **Task Queueing**: When tasks are submitted to the pool, they are placed in a queue. The pool distributes these tasks to available worker processes as they become free. This ensures that tasks are processed concurrently without the overhead of creating and destroying processes for each task.\n",
        "3. **Reusability**: Instead of creating a new process for every task, which can be resource-intensive and slow, a process pool reuses the existing processes. This reduces the overhead of constantly starting and terminating processes, leading to more efficient execution.\n",
        "4. **Automatic Load Balancing**: The process pool handles the distribution of tasks among the workers, ensuring that the workload is balanced. It assigns new tasks to the first available worker process.\n",
        "\n",
        "### How a Process Pool Improves Efficiency:\n",
        "1. **Reduced Overhead**: Creating a new process can be time-consuming and resource-intensive, especially if done repeatedly for multiple tasks. A process pool reduces this overhead by creating a set of worker processes at the start and reusing them, which saves time and system resources.\n",
        "2. **Efficient Task Distribution**: The pool automatically assigns tasks to available workers, preventing idle time. This ensures that all processes are being used optimally and tasks are processed as quickly as possible.\n",
        "3. **Scalability**: A process pool allows you to scale the number of processes based on the system’s capacity (e.g., the number of CPU cores). For example, you can create a pool with the same number of processes as the available CPU cores to maximize parallel processing without overwhelming the system.\n",
        "4. **Simplified Code Management**: Using a process pool abstracts away the complexities of managing multiple processes manually. This makes the code cleaner and easier to write, debug, and maintain.\n",
        "### When to Use a Process Pool:\n",
        "- **When there are many small, independent tasks**: Process pools are ideal for batch processing where multiple tasks can be executed independently.\n",
        "- **When tasks are CPU-bound**: Process pools can run multiple tasks concurrently across different CPU cores, bypassing the GIL.\n",
        "- **When you want to limit the number of concurrent processes**: To avoid overwhelming the system, a process pool can limit the number of processes running simultaneously.\n",
        "\n",
        "Overall, a process pool is a powerful tool that helps in efficiently managing multiple processes, reducing the overhead associated with process creation, and ensuring optimal resource utilization."
      ],
      "metadata": {
        "id": "iD88nT92RTg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with Pool(4) as pool:  # Creates a pool with 4 worker processes\n",
        "        numbers = [1, 2, 3, 4, 5]\n",
        "        results = pool.map(square, numbers)  # Distributes tasks to the pool\n",
        "        print(results)  # Output: [1, 4, 9, 16, 25]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ylT6lHTSD2D",
        "outputId": "76abcc38-8001-44a2-e631-9a2cbd8affa9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMZv7Cn8SHd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain what multiprocessing is and why it is used in python programs.\n",
        "\n",
        "**Multiprocessing** is a programming technique that allows a program to run multiple processes concurrently, each on its own CPU core, to achieve true parallelism. Unlike multithreading, which may be limited by the Global Interpreter Lock (GIL) in Python, multiprocessing bypasses this limitation by creating separate, independent processes, each with its own memory space.\n",
        "\n",
        "### Why Multiprocessing Is Used in Python Programs:\n",
        "1. **True Parallelism**:\n",
        "   - Python’s Global Interpreter Lock (GIL) allows only one thread to execute Python bytecode at a time, even on a multi-core CPU. This means that multithreading in Python does not provide true parallelism for CPU-bound tasks.\n",
        "   - Multiprocessing overcomes this limitation by running each process independently, allowing multiple CPU cores to be used simultaneously. Each process has its own GIL, so multiple processes can execute Python code at the same time, leading to true parallelism.\n",
        "\n",
        "2. **Efficient Use of Multi-Core CPUs**:\n",
        "   - Modern computers have multiple CPU cores, and multiprocessing enables a Python program to utilize them efficiently.\n",
        "   - For tasks that require heavy computation, like data processing, simulations, or mathematical calculations, multiprocessing allows these tasks to be divided among multiple cores, speeding up execution time.\n",
        "\n",
        "3. **Isolation and Fault Tolerance**:\n",
        "   - Each process in multiprocessing runs independently with its own memory space. This means that if one process crashes, it does not affect other processes.\n",
        "   - This isolation also helps prevent issues related to shared memory and race conditions, which can be common in multithreading scenarios.\n",
        "\n",
        "4. **Scalability**:\n",
        "   - Multiprocessing makes it easier to scale a program to handle larger workloads by simply adding more processes. Since the processes run independently, the program can scale across multiple cores or even multiple machines.\n",
        "   - It is ideal for tasks like batch processing, parallel computations, and workloads that can be distributed across several processes.\n",
        "\n",
        "### When to Use Multiprocessing:\n",
        "1. **CPU-bound tasks**: Tasks that require a lot of CPU power, such as numerical computations, data analysis, image processing, and machine learning model training. Multiprocessing allows these tasks to run faster by distributing the workload across multiple CPU cores.\n",
        "2. **Tasks that are independent of each other**: When tasks can run independently without needing to share state or data constantly, multiprocessing is a great choice. This independence avoids the overhead of managing shared resources.\n",
        "3. **When avoiding the GIL is necessary**: Since the GIL can be a bottleneck in CPU-bound tasks when using multithreading, switching to multiprocessing can bypass this issue and achieve true parallelism.\n",
        "### Summary:\n",
        "Multiprocessing is used in Python to overcome the limitations of the GIL and to make full use of multi-core processors. It enables true parallelism by running multiple processes concurrently, each on a separate core, which speeds up execution for CPU-bound tasks. It is also beneficial for its isolation, fault tolerance, and ability to scale easily across multiple cores or machines."
      ],
      "metadata": {
        "id": "4SK1eQJMSmsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def print_square(number):\n",
        "    print(f\"The square of {number} is {number * number}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    processes = []\n",
        "    for i in range(5):\n",
        "        process = Process(target=print_square, args=(i,))\n",
        "        processes.append(process)\n",
        "        process.start()\n",
        "\n",
        "    for process in processes:\n",
        "        process.join()  # Ensures all processes complete before exiting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEc4BDyzX-o5",
        "outputId": "2ee3e9fb-dd32-4e6a-a667-0da514e3cacc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The square of 0 is 0\n",
            "The square of 1 is 1\n",
            "The square of 2 is 4\n",
            "The square of 3 is 9\n",
            "The square of 4 is 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEefM7foYCcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write a python program using multiprocessing where  one thread  adds  numbers to a list , and another  thread removes  numbers from  the list , implement to a mechanism to avoid race condition using  threading lock .\n",
        "\n",
        "In Python's `multiprocessing`, threads can be managed using the `Thread` class from the `threading` module, even though the main focus is often on managing separate processes. To avoid race conditions when multiple threads are accessing and modifying a shared resource (like a list), we can use a `threading.Lock`.\n",
        "\n",
        "### Explanation:\n",
        "1. **Shared Resource**: We use a shared list created with `Manager().list()`. The `Manager` helps manage shared state between processes or threads, ensuring proper synchronization.\n",
        "2. **Lock Mechanism**: A `Lock` is used to avoid race conditions. When one thread is modifying the list (either adding or removing), the lock ensures that no other thread can access the list until the operation is complete.\n",
        "3. **Adding and Removing Threads**: Two threads are created—one to add numbers to the list and another to remove them. Both threads use the lock to prevent concurrent access to the shared list, thus avoiding a race condition.\n",
        "4. **Time Delays**: `time.sleep()` is added to simulate some delay, ensuring that the threads have overlapping execution times, which helps demonstrate the importance of using a lock.\n"
      ],
      "metadata": {
        "id": "UTE4bRZwYNxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Manager\n",
        "from threading import Thread, Lock\n",
        "import time\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_numbers(shared_list, lock):\n",
        "    for i in range(5):\n",
        "        with lock:\n",
        "            print(f\"Adding {i} to the list.\")\n",
        "            shared_list.append(i)\n",
        "        time.sleep(1)  # Simulate some delay\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_numbers(shared_list, lock):\n",
        "    for i in range(5):\n",
        "        time.sleep(1.5)  # Simulate some delay to ensure overlap with adding\n",
        "        with lock:\n",
        "            if shared_list:\n",
        "                removed_number = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_number} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a shared list using Manager\n",
        "    with Manager() as manager:\n",
        "        shared_list = manager.list()\n",
        "        lock = Lock()\n",
        "\n",
        "        # Creating two threads\n",
        "        add_thread = Thread(target=add_numbers, args=(shared_list, lock))\n",
        "        remove_thread = Thread(target=remove_numbers, args=(shared_list, lock))\n",
        "\n",
        "        # Start the threads\n",
        "        add_thread.start()\n",
        "        remove_thread.start()\n",
        "\n",
        "        # Wait for the threads to finish\n",
        "        add_thread.join()\n",
        "        remove_thread.join()\n",
        "\n",
        "        # Final state of the list\n",
        "        print(f\"Final list: {list(shared_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-cxNIwZaC68",
        "outputId": "729406c8-cb86-424e-b116-4bfd78d847ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 0 to the list.\n",
            "Adding 1 to the list.\n",
            "Removed 0 from the list.\n",
            "Adding 2 to the list.\n",
            "Removed 1 from the list.\n",
            "Adding 3 to the list.\n",
            "Adding 4 to the list.\n",
            "Removed 2 from the list.\n",
            "Removed 3 from the list.\n",
            "Removed 4 from the list.\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OmLt1IWQaGQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Describe the method and tools available in python for safely sharing data betweeen threads and process.\n",
        "\n",
        "In Python, sharing data between threads and processes can be challenging due to issues like race conditions, data inconsistency, and the Global Interpreter Lock (GIL). However, Python provides several methods and tools to handle these challenges safely. Here’s an overview:\n",
        "\n",
        "### 1. **Sharing Data Between Threads**\n",
        "Threads share the same memory space, making it easier to share data. However, this also means that race conditions can occur if multiple threads access shared data simultaneously. To address this, Python provides:\n",
        "\n",
        "#### a. **Locks (`threading.Lock`)**\n",
        "   - A `Lock` is a synchronization primitive that ensures that only one thread can access a shared resource at a time.\n",
        "   - Using a lock, you can prevent race conditions by making critical sections (code that modifies shared data) mutually exclusive.\n",
        "\n",
        "### Summary:\n",
        "- **Threads** share the same memory, so locks (`Lock`, `RLock`), condition variables, and queues are commonly used to handle shared data safely.\n",
        "- **Processes** do not share memory directly, so tools like `Queue`, `Pipe`, `Value`, `Array`, and `Manager` are used to facilitate inter-process communication and shared data management.\n",
        "- **Queues and Managers** simplify the process by managing locks internally, making them easier and safer to use when sharing data between threads or processes.\n",
        "\n",
        "By choosing the right tool based on the task's requirements, you can effectively share data while ensuring safety and consistency in multi-threaded and multi-process programs."
      ],
      "metadata": {
        "id": "OmQ13npxaIVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Manager\n",
        "\n",
        "with Manager() as manager:\n",
        "    shared_list = manager.list([1, 2, 3])\n",
        "    shared_dict = manager.dict({'a': 1, 'b': 2})\n"
      ],
      "metadata": {
        "id": "Ee5YVkEebpVf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tj3-QWivbr1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Discuss why it's crucial to handle exceptions in concurrent  programs and the techniques available   for doing so .\n",
        "\n",
        "Handling exceptions in concurrent programs is crucial because unhandled exceptions can lead to unexpected behaviors, resource leaks, deadlocks, or crashes. Concurrent programs, involving threads or processes, add complexity due to the parallel execution, which makes it harder to trace issues, debug, and ensure consistent system behavior. Therefore, robust exception handling is necessary to maintain program stability, provide error reporting, and ensure graceful recovery.\n",
        "\n",
        "### Why Exception Handling Is Crucial in Concurrent Programs:\n",
        "1. **Prevent Program Crashes**:\n",
        "   - In concurrent programs, if one thread or process throws an unhandled exception, it may cause the whole program to crash, disrupting the workflow and leading to data loss.\n",
        "   - Proper exception handling ensures that failures in one part of the program don’t bring down the entire application.\n",
        "\n",
        "2. **Resource Management**:\n",
        "   - Without exception handling, resources (like file handles, network connections, or memory) may not be properly released, leading to resource leaks.\n",
        "   - For example, if a thread is writing to a file and encounters an error, the file may remain open, blocking further operations.\n",
        "\n",
        "3. **Preventing Deadlocks and Inconsistent States**:\n",
        "   - An unhandled exception might leave locks or semaphores in an inconsistent state, leading to deadlocks.\n",
        "   - Ensuring that locks are always released, even in case of an error, helps maintain system stability.\n",
        "\n",
        "4. **Graceful Shutdown and Recovery**:\n",
        "   - In some cases, it is important to recover from errors and allow the system to continue functioning (e.g., retrying a network request).\n",
        "   - Proper exception handling allows the program to handle errors gracefully, logging the issue, retrying operations, or cleaning up resources before exiting.\n",
        "\n",
        "### Techniques for Handling Exceptions in Concurrent Programs:\n",
        "1. **Try-Except Blocks**:\n",
        "   - Use `try-except` blocks to catch exceptions where they are likely to occur, allowing you to handle them appropriately without crashing the entire program.\n",
        "   - Ensure that `try-except` blocks are used around critical sections of the code where errors are likely.\n",
        "2. **Exception Handling in Threads**:\n",
        "   - When using threads, unhandled exceptions can be missed because the main thread may not be aware of failures in other threads.\n",
        "   - To handle this, catch exceptions inside the thread function, log them, or propagate them to the main thread using a shared data structure.\n",
        "   \n",
        "3. **Using Future Objects (`concurrent.futures`)**:\n",
        "   - The `concurrent.futures` module provides `ThreadPoolExecutor` and `ProcessPoolExecutor` to handle threads and processes, respectively. It allows you to submit tasks and get `Future` objects that can be checked for exceptions.\n",
        "   - This makes it easier to capture exceptions and handle them appropriately, even when using multiple threads or processes.\n",
        "  \n",
        "4. **Using `multiprocessing.Pool` Exception Handling**:\n",
        "   - In multiprocessing, when using a `Pool`, any exceptions raised by worker processes are returned to the parent process. You can catch these exceptions using the `get()` method of the result object.\n",
        "   \n",
        "5. **Using Context Managers**:\n",
        "   - Context managers (`with` statements) can be used to ensure that resources are properly cleaned up, even if an exception occurs.\n",
        "   - This is especially useful when dealing with locks, files, or network connections.\n",
        "\n",
        "6. **Timeouts and Retry Mechanisms**:\n",
        "   - For tasks that may fail due to external reasons (e.g., network timeouts), consider implementing retries with backoff mechanisms to handle transient errors.\n",
        "\n",
        "### Summary:\n",
        "Proper exception handling in concurrent programs is essential to ensure that errors are caught, resources are managed effectively, and the system remains stable. Python provides several techniques, such as `try-except` blocks, context managers, thread-safe queues, and `concurrent.futures` for handling exceptions effectively. Additionally, implementing retry mechanisms, using locks, and managing resources carefully can help create robust and fault-tolerant concurrent applications."
      ],
      "metadata": {
        "id": "awFB7mbabtyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def perform_task():\n",
        "    # Simulate network operation\n",
        "    raise ConnectionError(\"Network issue\")\n",
        "\n",
        "for _ in range(3):  # Retry up to 3 times\n",
        "    try:\n",
        "        perform_task()\n",
        "        break  # Exit loop if successful\n",
        "    except ConnectionError as e:\n",
        "        print(f\"Retrying due to: {e}\")\n",
        "        time.sleep(1)  # Wait before retrying\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLeViqsxdPuP",
        "outputId": "a25e3816-30a4-407d-ec98-4f7ab92a7910"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrying due to: Network issue\n",
            "Retrying due to: Network issue\n",
            "Retrying due to: Network issue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eMTHlWixdRw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Create a program that uses a thread pool to calculate  the factorial of numbers from 1 to 10 concurrently , use concurrent futures . Thread pool Executor to manage the threads .\n",
        "\n",
        "Here is a Python program that uses the `concurrent.futures.ThreadPoolExecutor` to calculate the factorial of numbers from 1 to 10 concurrently. The `ThreadPoolExecutor` manages a pool of threads, allowing you to submit tasks and handle them efficiently:\n",
        "### Explanation:\n",
        "1. **ThreadPoolExecutor**:\n",
        "   - The `ThreadPoolExecutor` is used to manage a pool of threads. We set `max_workers=5`, which means up to 5 threads can run concurrently.\n",
        "   - You can adjust the number of workers depending on your system's capabilities and the task requirements.\n",
        "\n",
        "2. **Submitting Tasks**:\n",
        "   - The `submit()` method is used to submit tasks (in this case, calculating the factorial) to the thread pool. It returns a `Future` object, which represents the ongoing operation.\n",
        "   - A list comprehension is used to create tasks for numbers from 1 to 10.\n",
        "\n",
        "3. **Collecting Results**:\n",
        "   - The `as_completed()` function is used to iterate over the futures as they complete, regardless of the order they were started in.\n",
        "   - This allows you to process the results as soon as a thread finishes its calculation.\n",
        "\n",
        "4. **Function `calculate_factorial`**:\n",
        "   - This function simply uses `math.factorial()` to compute the factorial of the given number\n",
        "This program demonstrates how you can efficiently use `ThreadPoolExecutor` to handle concurrent tasks, taking advantage of multi-threading to run multiple operations simultaneously."
      ],
      "metadata": {
        "id": "n4UvlxgQdTL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import math\n",
        "\n",
        "# Function to calculate factorial\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a ThreadPoolExecutor with 5 worker threads\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        # Submit tasks to calculate factorials for numbers 1 to 10\n",
        "        futures = [executor.submit(calculate_factorial, i) for i in range(1, 11)]\n",
        "\n",
        "        # Collect and print results as they complete\n",
        "        for future in as_completed(futures):\n",
        "            result = future.result()\n",
        "            print(f\"Factorial calculated: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIdfYGrMebM8",
        "outputId": "3fe55a0e-d013-40d3-b2ce-bcb36c85c016"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial calculated: 720\n",
            "Factorial calculated: 2\n",
            "Factorial calculated: 24\n",
            "Factorial calculated: 5040\n",
            "Factorial calculated: 3628800\n",
            "Factorial calculated: 120\n",
            "Factorial calculated: 362880\n",
            "Factorial calculated: 6\n",
            "Factorial calculated: 40320\n",
            "Factorial calculated: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0q7qnaMoeecs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Create a python program that uses multiproessing . pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perfrom this computation using a pool of different sizes (e.gg.., 2,4,8 process ).\n",
        "\n",
        "Here is a Python program that uses the `multiprocessing.Pool` to compute the square of numbers from 1 to 10 in parallel. It also measures the time taken to perform the computations using different pool sizes (2, 4, and 8 processes).\n",
        "\n",
        "### Explanation:\n",
        "1. **Multiprocessing Pool**:\n",
        "   - The `Pool` object allows you to run tasks in parallel across multiple processes. Each process in the pool will handle a separate part of the task concurrently.\n",
        "   - The `map()` method of `Pool` distributes the input data across the processes, collects the results, and returns them as a list.\n",
        "\n",
        "2. **Measuring Time**:\n",
        "   - The program uses `time.time()` to record the start and end times of the computation, and it calculates the time taken to perform the task.\n",
        "   - This is done separately for different pool sizes (2, 4, and 8 processes) to compare performance.\n",
        "\n",
        "3. **Running the Program**:\n",
        "   - The program will run the square computations for the numbers 1 to 10 using pools of different sizes. Each run will print the results and the time taken for that particular pool size."
      ],
      "metadata": {
        "id": "_wad1N4WegIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure time taken with different pool sizes\n",
        "def measure_time(pool_size):\n",
        "    numbers = range(1, 11)\n",
        "\n",
        "    # Start the timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a Pool of the specified size\n",
        "    with Pool(pool_size) as pool:\n",
        "        # Compute the squares in parallel\n",
        "        results = pool.map(compute_square, numbers)\n",
        "\n",
        "    # Stop the timer\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Print the results and the time taken\n",
        "    print(f\"Pool size: {pool_size}, Results: {results}, Time taken: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test with different pool sizes\n",
        "    for size in [2, 4, 8]:\n",
        "        measure_time(size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xawshGTGf-4L",
        "outputId": "3baa5277-8f92-4144-8dc1-fbe9f2d3bbb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0291 seconds\n",
            "Pool size: 4, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0467 seconds\n",
            "Pool size: 8, Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken: 0.0935 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6_IUJCjgCMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}